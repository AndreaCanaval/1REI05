{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1d690b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalgraphicalmodels import CausalGraphicalModel\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import statsmodels.api as sm \n",
    "import statsmodels.formula.api as smf \n",
    "from itertools import combinations \n",
    "import plotnine as p\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import linearmodels.iv.model as lm\n",
    "from linearmodels.iv import IV2SLS\n",
    "from statsmodels.iolib.summary2 import summary_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3796c52",
   "metadata": {},
   "source": [
    "# Instrumental Variables (IV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1835585c",
   "metadata": {},
   "source": [
    "## Intuition of Instrumental Variables\n",
    "\n",
    "### Canonical IV Dag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f0024a",
   "metadata": {},
   "source": [
    "To understand the instrumental variables estimator, it is helpful to start with a DAG that shows a chain of causal effects that contains all the information needed to understand the instrumental variables strategy. \n",
    "\n",
    "First, notice the backdoor path between $D$ and $Y$: $D \\leftarrow U \\rightarrow Y$. Furthermore, note that $U$ is unobserved by the econometrician, which causes the backdoor path to remain open. If we have this kind of selection on unobservables, then there does not exist a conditioning strategy that will satisfy the backdoor criterion (in our data). But, before we throw up our arms, let’s look at how $Z$ operates through these pathways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f6011cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 4.0.0 (20220529.0937)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"142pt\" height=\"196pt\"\n",
       " viewBox=\"0.00 0.00 142.00 196.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 192)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-192 138,-192 138,4 -4,4\"/>\n",
       "<!-- Z -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Z</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"31\" cy=\"-166\" rx=\"27\" ry=\"18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"31\" cy=\"-166\" rx=\"31\" ry=\"22\"/>\n",
       "<text text-anchor=\"middle\" x=\"31\" y=\"-162.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Z</text>\n",
       "</g>\n",
       "<!-- D -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"52\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"52\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">D</text>\n",
       "</g>\n",
       "<!-- Z&#45;&gt;D -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Z&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M36.85,-144.39C39.19,-136.15 41.91,-126.55 44.4,-117.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47.81,-118.58 47.17,-108.01 41.08,-116.67 47.81,-118.58\"/>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"79\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"79\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>D&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M58.4,-72.41C61.51,-64.34 65.33,-54.43 68.83,-45.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"72.13,-46.55 72.46,-35.96 65.6,-44.03 72.13,-46.55\"/>\n",
       "</g>\n",
       "<!-- U -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>U</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"107\" cy=\"-166\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"107\" y=\"-162.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">U</text>\n",
       "</g>\n",
       "<!-- U&#45;&gt;D -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>U&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M95.6,-149.67C88.13,-139.61 78.21,-126.27 69.72,-114.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"72.35,-112.51 63.57,-106.57 66.73,-116.68 72.35,-112.51\"/>\n",
       "</g>\n",
       "<!-- U&#45;&gt;Y -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>U&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.73,-147.97C98.93,-122.91 89.91,-75.87 84.19,-46.06\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"87.57,-45.09 82.25,-35.93 80.69,-46.41 87.57,-45.09\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1d1eb42b508>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv = CausalGraphicalModel(nodes = [\"Z\",\"D\",\"Y\",\"U\"],\n",
    "                          edges = [(\"Z\",\"D\"),\n",
    "                                   (\"D\",\"Y\"),\n",
    "                                  (\"U\",\"D\"),\n",
    "                                  (\"U\",\"Y\")])\n",
    "iv = iv.do('Z')\n",
    "iv.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fb66a3",
   "metadata": {},
   "source": [
    "First, there is a mediated pathway from $Z$ to $Y$ via $D$. When $Z$ varies, $D$ varies, which causes $Y$ to change. But, even though $Y$ is varying when $Z$ varies, notice that $Y$ is only varying **because** $D$ has varied. You sometimes hear people describe this as the “only through” assumption. That is, $Z$ affects $Y$ “**only through**” $D$.\n",
    "\n",
    "Imagine this for a moment though. Imagine $D$ consists of people making choices. Sometimes these choices affect $Y$, and sometimes these choices are merely correlated with changes in $Y$ due to unobserved changes in $U$. But along comes some shock, $Z$, which induces some but not all of the people in $D$ to make different decisions. What will happen?\n",
    "\n",
    "Well, for one, when those people’s decisions change, $Y$ will change too, because of the causal effect. But all of the correlation between $D$ and $Y$ in that situation will reflect the causal effect. The reason is that $D$ is a collider along the backdoor path between $Z$ and $Y$.\n",
    "\n",
    "Moving along, notice that we drew the DAG such that $Z$ is independent of $U$. You can see this because $D$ is a collider along the $Z \\rightarrow D \\leftarrow U$ path, which implies that $Z$ and $U$ are independent. This is called the “exclusion restriction,” which we will discuss in more detail later. But briefly, the IV estimator assumes that $Z$ is independent of the variables that determine $Y$ except for $D$.\n",
    "\n",
    "Second, $Z$ is correlated with $D$, and because of its correlation with $D$ (and $D$’s effect on $Y$), $Z$ is correlated with $Y$ but only through its effect on $D$. This relationship between $Z$ and $D$ is called the “first stage” because of the two-stage least squares estimator, which is a kind of IV estimator. The reason it is only correlated with $Y$ via $D$ is because $D$ is a collider along the path $Z \\rightarrow D \\leftarrow U \\rightarrow Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369c42e0",
   "metadata": {},
   "source": [
    "## Applications\n",
    "\n",
    "### College in the county\n",
    "\n",
    "We will look at the returns to schooling since it is such a historically popular topic for causal questions in labor. In this application, we will simply estimate a 2SLS model, calculate the first-stage *F statistic*, and compare the 2SLS results with the OLS results.\n",
    "\n",
    "The data comes from the NLS Young Men Cohort of the National Longitudinal Survey. This data began in 1966 with 5,525 men aged 14–24 and continued to follow up with them through 1981. These data come from 1966, the baseline survey, and there are a number of questions related to local labor-markets. One of them is whether the respondent lives in the same county as a 4-year (and a 2-year) college.\n",
    "\n",
    "Card (1995) is interested in estimating the following regression equation:\n",
    "\n",
    "$$ Y_{i} = \\alpha + \\delta S_{i} + \\gamma X_{i} + \\epsilon_{i} $$\n",
    "\n",
    "where $Y$ is log earnings, $S$ is years of schooling, $X$ is a matrix of exogenous covariates, and $\\epsilon$ is an error term that contains, among other things, unobserved ability. Under the assumption that  $\\epsilon$ contains ability, and ability is correlated with schooling, then $C(S, \\epsilon) \\neq 0$ and therefore schooling is biased. Card (1995) proposes therefore an instrumental variables strategy whereby he will instrument for schooling with the college-in-the-county dummy variable.\n",
    "\n",
    "It is worth asking ourselves why the presence of a 4-year college in one’s county would increase schooling. The main reason I can think of is that the presence of the 4-year college increases the likelihood of going to college by lowering the costs, since the student can live at home. This therefore means that we are selecting on a group of compliers whose behavior is affected by the variable. Some kids, in other words, will always go to college regardless of whether a college is in their county, and some will never go despite the presence of the nearby college. But there may exist a group of compliers who go to college only because their county has a college, and if I’m right that this is primarily picking up people going because they can attend while living at home, then it’s necessarily people at some margin who attend only because college became slightly cheaper. This is, in other words, a group of people who are liquidity constrained. And if we believe the returns to schooling for this group are different from those of the always-takers, then our estimates may not represent the ATE. Rather, they would represent the LATE. But in this case, that might actually be an interesting parameter since it gets at the issue of lowering costs of attendance for poorer families."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c862dc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nearc2</th>\n",
       "      <th>nearc4</th>\n",
       "      <th>educ</th>\n",
       "      <th>age</th>\n",
       "      <th>fatheduc</th>\n",
       "      <th>motheduc</th>\n",
       "      <th>weight</th>\n",
       "      <th>momdad14</th>\n",
       "      <th>sinmom14</th>\n",
       "      <th>...</th>\n",
       "      <th>KWW</th>\n",
       "      <th>IQ</th>\n",
       "      <th>married</th>\n",
       "      <th>libcrd14</th>\n",
       "      <th>exper</th>\n",
       "      <th>lwage</th>\n",
       "      <th>expersq</th>\n",
       "      <th>u_lwage</th>\n",
       "      <th>lwage_hat</th>\n",
       "      <th>u_educ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158413.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.306275</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.198047</td>\n",
       "      <td>6.108228</td>\n",
       "      <td>-3.067539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>380166.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.175867</td>\n",
       "      <td>81.0</td>\n",
       "      <td>-0.211160</td>\n",
       "      <td>6.387027</td>\n",
       "      <td>-1.727562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>367470.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.580639</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.204719</td>\n",
       "      <td>6.375920</td>\n",
       "      <td>1.012975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>380166.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.521461</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-0.967905</td>\n",
       "      <td>6.489366</td>\n",
       "      <td>-2.253536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>367470.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.591674</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.125173</td>\n",
       "      <td>6.466501</td>\n",
       "      <td>1.090437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  nearc2  nearc4  educ   age  fatheduc  motheduc    weight  momdad14  \\\n",
       "0  2.0     0.0     0.0   7.0  29.0       NaN       NaN  158413.0       1.0   \n",
       "1  3.0     0.0     0.0  12.0  27.0       8.0       8.0  380166.0       1.0   \n",
       "2  4.0     0.0     0.0  12.0  34.0      14.0      12.0  367470.0       1.0   \n",
       "3  5.0     1.0     1.0  11.0  27.0      11.0      12.0  380166.0       1.0   \n",
       "4  6.0     1.0     1.0  12.0  34.0       8.0       7.0  367470.0       1.0   \n",
       "\n",
       "   sinmom14  ...   KWW     IQ  married  libcrd14  exper     lwage  expersq  \\\n",
       "0       0.0  ...  15.0    NaN      1.0       0.0   16.0  6.306275    256.0   \n",
       "1       0.0  ...  35.0   93.0      1.0       1.0    9.0  6.175867     81.0   \n",
       "2       0.0  ...  42.0  103.0      1.0       1.0   16.0  6.580639    256.0   \n",
       "3       0.0  ...  25.0   88.0      1.0       1.0   10.0  5.521461    100.0   \n",
       "4       0.0  ...  34.0  108.0      1.0       0.0   16.0  6.591674    256.0   \n",
       "\n",
       "    u_lwage  lwage_hat    u_educ  \n",
       "0  0.198047   6.108228 -3.067539  \n",
       "1 -0.211160   6.387027 -1.727562  \n",
       "2  0.204719   6.375920  1.012975  \n",
       "3 -0.967905   6.489366 -2.253536  \n",
       "4  0.125173   6.466501  1.090437  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "def read_data(file): \n",
    "    return pd.read_stata(\"https://raw.github.com/scunning1975/mixtape/master/\" + file)\n",
    "\n",
    "card = read_data(\"card.dta\")\n",
    "card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8f19070e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>   0.305</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.303</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   219.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 17 Aug 2022</td> <th>  Prob (F-statistic):</th> <td>1.69e-232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:41:36</td>     <th>  Log-Likelihood:    </th> <td> -1278.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3010</td>      <th>  AIC:               </th> <td>   2571.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3003</td>      <th>  BIC:               </th> <td>   2613.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    5.0642</td> <td>    0.064</td> <td>   79.594</td> <td> 0.000</td> <td>    4.939</td> <td>    5.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>      <td>    0.0711</td> <td>    0.003</td> <td>   20.439</td> <td> 0.000</td> <td>    0.064</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exper</th>     <td>    0.0342</td> <td>    0.002</td> <td>   15.459</td> <td> 0.000</td> <td>    0.030</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>     <td>   -0.1654</td> <td>    0.018</td> <td>   -9.408</td> <td> 0.000</td> <td>   -0.200</td> <td>   -0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>south</th>     <td>   -0.1325</td> <td>    0.015</td> <td>   -8.855</td> <td> 0.000</td> <td>   -0.162</td> <td>   -0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>married</th>   <td>   -0.0358</td> <td>    0.003</td> <td>  -10.542</td> <td> 0.000</td> <td>   -0.042</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>smsa</th>      <td>    0.1751</td> <td>    0.015</td> <td>   11.338</td> <td> 0.000</td> <td>    0.145</td> <td>    0.205</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>52.534</td> <th>  Durbin-Watson:     </th> <td>   1.853</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  68.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.231</td> <th>  Prob(JB):          </th> <td>1.60e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.575</td> <th>  Cond. No.          </th> <td>    154.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                       0.305\n",
       "Model:                            OLS   Adj. R-squared:                  0.303\n",
       "Method:                 Least Squares   F-statistic:                     219.1\n",
       "Date:                Wed, 17 Aug 2022   Prob (F-statistic):          1.69e-232\n",
       "Time:                        23:41:36   Log-Likelihood:                -1278.7\n",
       "No. Observations:                3010   AIC:                             2571.\n",
       "Df Residuals:                    3003   BIC:                             2613.\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      5.0642      0.064     79.594      0.000       4.939       5.189\n",
       "educ           0.0711      0.003     20.439      0.000       0.064       0.078\n",
       "exper          0.0342      0.002     15.459      0.000       0.030       0.039\n",
       "black         -0.1654      0.018     -9.408      0.000      -0.200      -0.131\n",
       "south         -0.1325      0.015     -8.855      0.000      -0.162      -0.103\n",
       "married       -0.0358      0.003    -10.542      0.000      -0.042      -0.029\n",
       "smsa           0.1751      0.015     11.338      0.000       0.145       0.205\n",
       "==============================================================================\n",
       "Omnibus:                       52.534   Durbin-Watson:                   1.853\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               68.142\n",
       "Skew:                          -0.231   Prob(JB):                     1.60e-15\n",
       "Kurtosis:                       3.575   Cond. No.                         154.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OLS\n",
    "ols_reg = sm.OLS.from_formula(\"lwage ~ educ + exper + black + south + married + smsa\", \n",
    "              data = card).fit()\n",
    "\n",
    "ols_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "08d684c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are null values in the dataset, we will fill them with 0\n",
    "card['married'] = card['married'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5d4ff07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>IV-2SLS Estimation Summary</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>0.2428</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th> <td>0.2413</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>3010</td>       <th>  F-statistic:       </th> <td>884.54</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, Aug 17 2022</td> <th>  P-value (F-stat)   </th> <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:41:32</td>     <th>  Distribution:      </th> <td>chi2(6)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cov. Estimator:</th>        <td>robust</td>      <th>                     </th>    <td></td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td></td>         <th>                     </th>    <td></td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Parameter Estimates</caption>\n",
       "<tr>\n",
       "      <td></td>      <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th>  <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>4.0998</td>    <td>0.8209</td>   <td>4.9942</td>  <td>0.0000</td>   <td>2.4909</td>   <td>5.7088</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>      <td>-0.1110</td>   <td>0.0493</td>   <td>-2.2504</td> <td>0.0244</td>   <td>-0.2076</td>  <td>-0.0143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exper</th>      <td>0.0571</td>    <td>0.0195</td>   <td>2.9262</td>  <td>0.0034</td>   <td>0.0189</td>   <td>0.0953</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>married</th>    <td>-0.0318</td>   <td>0.0050</td>   <td>-6.3846</td> <td>0.0000</td>   <td>-0.0415</td>  <td>-0.0220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>smsa</th>       <td>0.1448</td>    <td>0.0302</td>   <td>4.8025</td>  <td>0.0000</td>   <td>0.0857</td>   <td>0.2039</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>south</th>      <td>-0.1128</td>   <td>0.0228</td>   <td>-4.9550</td> <td>0.0000</td>   <td>-0.1574</td>  <td>-0.0682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>       <td>0.1279</td>    <td>0.0484</td>   <td>2.6438</td>  <td>0.0082</td>   <td>0.0331</td>   <td>0.2227</td> \n",
       "</tr>\n",
       "</table><br/><br/>Endogenous: educ<br/>Instruments: nearc4<br/>Robust Covariance (Heteroskedastic)<br/>Debiased: False"
      ],
      "text/plain": [
       "<class 'linearmodels.compat.statsmodels.Summary'>\n",
       "\"\"\"\n",
       "                          IV-2SLS Estimation Summary                          \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                      0.2428\n",
       "Estimator:                    IV-2SLS   Adj. R-squared:                 0.2413\n",
       "No. Observations:                3010   F-statistic:                    884.54\n",
       "Date:                Wed, Aug 17 2022   P-value (F-stat)                0.0000\n",
       "Time:                        23:41:32   Distribution:                  chi2(6)\n",
       "Cov. Estimator:                robust                                         \n",
       "                                                                              \n",
       "                             Parameter Estimates                              \n",
       "==============================================================================\n",
       "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      4.0998     0.8209     4.9942     0.0000      2.4909      5.7088\n",
       "black         -0.1110     0.0493    -2.2504     0.0244     -0.2076     -0.0143\n",
       "exper          0.0571     0.0195     2.9262     0.0034      0.0189      0.0953\n",
       "married       -0.0318     0.0050    -6.3846     0.0000     -0.0415     -0.0220\n",
       "smsa           0.1448     0.0302     4.8025     0.0000      0.0857      0.2039\n",
       "south         -0.1128     0.0228    -4.9550     0.0000     -0.1574     -0.0682\n",
       "educ           0.1279     0.0484     2.6438     0.0082      0.0331      0.2227\n",
       "==============================================================================\n",
       "\n",
       "Endogenous: educ\n",
       "Instruments: nearc4\n",
       "Robust Covariance (Heteroskedastic)\n",
       "Debiased: False\n",
       "\"\"\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2SLS\n",
    "iv_reg = IV2SLS.from_formula(\"lwage ~  1 + exper + black + south + married + smsa + [educ ~ nearc4 ]\", card).fit()\n",
    "iv_reg.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95243ffd",
   "metadata": {},
   "source": [
    "First, we report our OLS results. For every one year additional of schooling, respondents’ earnings increase by approximately 7.1%. Next we estimated 2SLS. Here we find a much larger return to schooling than we had found using OLS—around 75% larger in fact. The F statistic exceeds 15, suggesting we don’t have a weak instrument problem. The return to schooling associated with this 2SLS estimate is 0.127—that is, for every additional year of schooling, earnings increase by 12.7%. Other covariates are listed if you’re interested in studying them as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
